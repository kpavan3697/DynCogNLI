# DynCogNLI

A research-driven NLP system for **dynamic commonsense inference**, enabling models to adapt in real time to changing contexts and inputs.

---

## âš™ï¸ Setup

The following commands help you create and activate a virtual environment.  
This is used to create an isolated Python environment for your project.

```bash
python -m venv .venv
```

Activate the environment:

- **Windows (PowerShell)**
  ```powershell
  .venv\Scripts\Activate.ps1
  ```
- **Windows (CMD)**
  ```cmd
  .venv\Scripts\activate.bat
  ```
- **Linux / macOS**
  ```bash
  source .venv/bin/activate
  ```

Install required libraries:

```bash
pip install -r requirements.txt
```

---

## ğŸ‹ï¸ Training the Model

To train the Graph Attention Network (GAT) with ConceptNet and ATOMIC datasets:

```bash
python train_gat.py --atomic data/atomic2020/train.csv --batch-size 32
```

Arguments:

- `--atomic` â†’ Path to ATOMIC dataset
- `--batch-size` â†’ Training batch size

---

To train the baseline model with ConceptNet and ATOMIC datasets:

```bash
python train_baseline.py
```

Optional Arguments:

- `--epochs` â†’ Path to ATOMIC dataset
- `--batch-size` â†’ Batch size for training
- `--lr` â†’ Learning rate for the optimizer

If no arguments are provided, the default configuration below is used:

- `--epochs` = 20
- `--batch-size` = 8
- `--lr` = 1e-3

---

After training the models, run the following command. This will update the aggregate_summary.json, which is used to display the metrics on the UI.

```bash
python .\evaluation\evaluator.py
```

---

## ğŸ“Š Evaluation

The `eval_gat.py` script evaluates the performance of the trained GAT model. It loads a checkpoint, prepares evaluation data, runs inference, and computes metrics.

Key Functions:

- **Model Loading** â†’ Loads a pre-trained checkpoint (`.pth`)
- **Data Preparation** â†’ Prepares subgraphs + ground-truth persona labels
- **Inference** â†’ Runs predictions on evaluation data
- **Metrics** â†’ Accuracy, Precision, Recall, F1-score

Run evaluation with:

```bash
python -m tools.eval_gat --atomic data/atomic2020/train.csv --checkpoint models/persona_gat_model.pth --device cpu --terms [TERM1] [TERM2] "[MULTI-WORD TERM]"
```

---

## ğŸ” Checkpoint Inspection

The `inspect_checkpoint.py` script helps debug and verify PyTorch model checkpoint files (`.pth`) without needing the full model architecture.

Key Features:

- Displays **top-level keys** (`model_state_dict`, `epoch`, `optimizer_state_dict`, etc.)
- Lists **parameter names + tensor shapes**
- Shows **metadata** (`input_dim`, `hidden_dim`, `output_dim`)

Usage:

```bash
python tools/inspect_checkpoint.py models/persona_gat_model.pth
```

---

## ğŸŒ Streamlit Interface

The project includes a **Streamlit app** for interactive exploration.

Run with:

```bash
streamlit run app.py --server.runOnSave false
```

Access in your browser:

- Local: [http://localhost:8501](http://localhost:8501)
- Network: `http://<your-ip>:8501`

---

## ğŸ“‚ Project Structure

```
DynCogNLI/
â”œâ”€â”€ README.md
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ config.json
â”œâ”€â”€ app.py
â”œâ”€â”€ train_gat.py
â”œâ”€â”€ train_baseline.py
â”œâ”€â”€ run_inference.py
â”œâ”€â”€ aggregate_summary.json
â”œâ”€â”€ evaluated_results.json
â”‚
â”œâ”€â”€ context/
â”‚   â”œâ”€â”€ context_encoder.py
â”‚   â”œâ”€â”€ context_manager.py
â”‚   â”œâ”€â”€ real_time_updater.py
â”‚   â”œâ”€â”€ response_generator.py
â”‚   â””â”€â”€ transformer_encoder.py
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ atomic2020/
â”‚   â”‚   â””â”€â”€ train.csv
â”‚   â”œâ”€â”€ conceptnet/
â”‚   â”‚   â””â”€â”€ conceptnet.db
â”‚   â””â”€â”€ kg_mappings/
â”‚       â”œâ”€â”€ node2id.json
â”‚       â””â”€â”€ rel2id.json
â”‚
â”œâ”€â”€ evaluation/
â”‚   â”œâ”€â”€ dialogue_metric.py
â”‚   â”œâ”€â”€ evaluation_data.json
â”‚   â”œâ”€â”€ evaluation_results.json
â”‚   â”œâ”€â”€ evaluator.py
â”‚   â””â”€â”€ get_evaluation_stats.py
â”‚
â”œâ”€â”€ explanation_images/
â”‚
â”œâ”€â”€ knowledge/
â”‚   â”œâ”€â”€ common_sense_client.py
â”‚   â”œâ”€â”€ graph_builder.py
â”‚   â”œâ”€â”€ graph_visualizer.py
â”‚   â”œâ”€â”€ interactive_visualizer.py
â”‚   â”œâ”€â”€ retriever.py
â”‚   â””â”€â”€ visualizer.py
â”‚
â”œâ”€â”€ llm/
â”‚   â””â”€â”€ llm_responder.py
â”‚
â”œâ”€â”€ models/
â”‚   â””â”€â”€ persona_gat_model.pth
â”‚
â”œâ”€â”€ preprocessing/
â”‚   â”œâ”€â”€ atomic_loader.py
â”‚   â””â”€â”€ conceptnet_loader.py
â”‚   â””â”€â”€ mock_data_generator.py
â”‚
â”œâ”€â”€ reasoning/
â”‚   â”œâ”€â”€ gat_model.py
â”‚   â”œâ”€â”€ graph_builder.py
â”‚   â”œâ”€â”€ multi_hop_reasoner.py
â”‚   â””â”€â”€ simple_model.py
â”‚
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ run_streamlit.bat
â”‚   â”œâ”€â”€ run_streamlit.ps1
â”‚   â””â”€â”€ run_streamlit.sh
â”‚
â”œâ”€â”€ tools/
â”‚   â”œâ”€â”€ app copy.py
â”‚   â”œâ”€â”€ eval_gat.py
â”‚   â””â”€â”€ inspect_checkpoint.py
â”‚
â”œâ”€â”€ utils/
â”‚   â””â”€â”€ graph_utils.py
â”‚
â””â”€â”€ visualization/
    â””â”€â”€ graph_plotter.py

```

---

## Available Scripts

- `train_gat.py` â†’ Train the GAT model
- `tools/eval_gat.py` â†’ Evaluate the trained model
- `tools/inspect_checkpoint.py` â†’ Inspect checkpoint contents
- `app.py` â†’ Run Streamlit interface

---

## Example Workflow

1. **Setup environment**

   ```bash
   python -m venv .venv
   .venv\Scripts\activate
   pip install -r requirements.txt
   ```

2. **Train the model**

   ```bash
   python train_gat.py --atomic data/atomic2020/train.csv --batch-size 8
   ```

3. **Evaluate model performance**

   ```bash
   python -m tools.eval_gat --atomic data/atomic2020/train.csv --checkpoint models/persona_gat_model.pth --device cpu --terms [TERM1] [TERM2] "[MULTI-WORD TERM]"
   ```

4. **Inspect a checkpoint**

   ```bash
   python tools/inspect_checkpoint.py models/persona_gat_model.pth
   ```

5. **Launch Streamlit app**
   ```bash
   streamlit run app.py --server.runOnSave false
   ```

---
